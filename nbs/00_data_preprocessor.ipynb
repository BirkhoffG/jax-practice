{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:41:24.432186745Z",
     "start_time": "2023-10-20T13:41:24.391318017Z"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp data_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "`DataPreprocessor` transforms *individual* features into numerical representations for the machine learning and recourse generation workflows. \n",
    "It can be considered as a drop-in jax-friendly replacement to the \n",
    "[sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "The supported preprocessing methods include `MinMaxScaler` and `OneHotEncoder`. \n",
    "\n",
    "However, unlike the `DataPreprocessor` [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module,\n",
    "all of the data preprocessors work only with single features (e.g., Dim: `(B, 1)`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:41:24.482851260Z",
     "start_time": "2023-10-20T13:41:24.399346476Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:41:24.483101975Z",
     "start_time": "2023-10-20T13:41:24.441411876Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as skp\n",
    "from fastcore.test import test_fail\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:41:24.483209611Z",
     "start_time": "2023-10-20T13:41:24.441532189Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataPreprocessor:\n",
    "    \n",
    "    def fit(self, xs, y=None):\n",
    "        \"\"\"Fit the preprocessor with `xs` and `y`.\"\"\"\n",
    "        self._fit(xs, y)\n",
    "\n",
    "    def transform(self, xs):\n",
    "        \"\"\"Transform `xs`.\"\"\"\n",
    "        self._transform(xs)\n",
    "\n",
    "    def fit_transform(self, xs, y=None):\n",
    "        \"\"\"Fit the preprocessor with `xs` and `y`, then transform `xs`.\"\"\"\n",
    "        self.fit(xs, y)\n",
    "        return self.transform(xs)\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        \"\"\"Inverse transform `xs`.\"\"\"\n",
    "        self._inverse_transform(xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T13:41:24.483297098Z",
     "start_time": "2023-10-20T13:41:24.441609497Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_xs(xs: np.ndarray, name: str):\n",
    "    \"\"\"Check if `xs` is a 1D array with shape (n_samples,) or a 2D array with shape (n_samples, 1).\"\"\"\n",
    "    if xs.ndim > 2 or (xs.ndim == 2 and xs.shape[1] != 1):\n",
    "        raise ValueError(f\"`{name}` only supports array with a single feature, but got shape={xs.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T14:40:53.906506950Z",
     "start_time": "2023-10-20T14:40:53.893914978Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class MinMaxScaler(DataPreprocessor):         \n",
    "    def fit(self, xs, y=None):\n",
    "        _check_xs(xs, name=\"MinMaxScaler\")\n",
    "        self.min_ = xs.min(axis=0)\n",
    "        self.max_ = xs.max(axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, xs):\n",
    "        if self.min_ == self.max_:\n",
    "            # return xs\n",
    "            return np.zeros(xs.shape)\n",
    "        return (xs - self.min_) / (self.max_ - self.min_)\n",
    "    \n",
    "    def inverse_transform(self, xs):\n",
    "        if self.min_ + self.max_ == 0:\n",
    "            return xs\n",
    "        elif self.min_ == self.max_ == 1:\n",
    "            return xs\n",
    "        # if (self.min_ == self.max_):\n",
    "        #     return xs\n",
    "        return xs * (self.max_ - self.min_) + self.min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "#!!! Do not edit things below.\n",
    "# `xs` represents 100 data points with 1 feature.\n",
    "xs = np.random.randn(100, )\n",
    "scaler = MinMaxScaler()\n",
    "transformed_xs = scaler.fit_transform(xs)\n",
    "assert transformed_xs.shape == (100, )\n",
    "assert np.allclose(xs, scaler.inverse_transform(transformed_xs))\n",
    "# Test correctness \n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1)).reshape(100,)\n",
    ")\n",
    "\n",
    "# Can also represented in 2D array.\n",
    "xs = xs.reshape(100, 1)\n",
    "scaler = MinMaxScaler()\n",
    "transformed_xs = scaler.fit_transform(xs)\n",
    "assert np.allclose(xs, scaler.inverse_transform(transformed_xs))\n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1))\n",
    ")\n",
    "\n",
    "# It will fail if `xs` has more than 1 feature.\n",
    "xs = xs.reshape(50, 2)\n",
    "scaler = MinMaxScaler()\n",
    "test_fail(lambda: scaler.fit_transform(xs), \n",
    "          contains=\"`MinMaxScaler` only supports array with a single feature\")\n",
    "\n",
    "# The above implementation will fail here. Fix it.\n",
    "xs = np.ones((100, 1))\n",
    "scaler = MinMaxScaler()\n",
    "transformed_xs = scaler.fit_transform(xs)\n",
    "# print(\"transformed_xs\", transformed_xs)\n",
    "# print(\"Bro here\", skp.MinMaxScaler().fit_transform(xs.reshape(100, 1)))\n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1))\n",
    ")\n",
    "print(\"xs\", xs)\n",
    "print(\"transformed_xs\", transformed_xs)\n",
    "print(\"transformed_xs\", scaler.inverse_transform(transformed_xs))\n",
    "assert np.allclose(xs, scaler.inverse_transform(transformed_xs))\n",
    "# print(\"transformed_xs\", transformed_xs)\n",
    "# print(\"xs.reshape(100,1)\", xs.reshape(100,1))\n",
    "# print(\"skp.MinMaxScaler().fit_transform(xs.reshape(100,1))\", skp.MinMaxScaler().fit_transform(xs.reshape(100, 1)))\n",
    "print(\"fit_transform(xs.reshape(100,1))\", scaler.fit_transform(xs.reshape(100,1)))\n",
    "print(\"MinMaxScaler().fit_transform(xs.reshape(100,1))\", skp.MinMaxScaler().fit_transform(xs.reshape(100,1)))\n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T14:40:54.785935620Z",
     "start_time": "2023-10-20T14:40:54.778003378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "#| export\n",
    "# class OneHotEncoder(DataPreprocessor):\n",
    "#     \"\"\"One-hot encoder for a single categorical feature.\"\"\"\n",
    "#     \n",
    "#         # def __init__(self, categories=None):\n",
    "#         # \"\"\"\n",
    "#         # Initialize the OneHotEncoder.\n",
    "#         # \n",
    "#         # Args:\n",
    "#         #     categories: A list of categories to encode. If None, the categories will be inferred from the data.\n",
    "#         # \"\"\"\n",
    "#         # self.categories = categories\n",
    "# \n",
    "#     def __init__(self):\n",
    "#         self.categories = None\n",
    "# \n",
    "#     def fit(self, xs, y=None):\n",
    "#         \"\"\"Fit the OneHotEncoder with `xs`.\"\"\"\n",
    "#         # _check_xs(xs, name=\"OneHotEncoder\")\n",
    "#         # self.categories_ = np.unique(xs)\n",
    "#         # return self\n",
    "#                 # If categories are not specified, infer them from the data.\n",
    "#         self.categories = set()\n",
    "#         for x in xs:\n",
    "#             self.categories.add(x)\n",
    "#         ...\n",
    "# \n",
    "#     def transform(self, xs):\n",
    "#         \"\"\"Transform `xs`.\"\"\"\n",
    "#         # Check if the input is a single column.\n",
    "#         # xs = xs[:, np.newaxis]\n",
    "#         # \n",
    "#         # # Check if the input categories are the same as the fitted categories.\n",
    "#         # if not np.array_equal(np.unique(xs), self.categories_):\n",
    "#         #     raise ValueError(\"The input categories must be the same as the fitted categories.\")\n",
    "#         # \n",
    "#         # # Create a one-hot encoding for each input category.\n",
    "#         # one_hot = np.zeros((xs.shape[0], len(self.categories_)))\n",
    "#         # for i, category in enumerate(self.categories_):\n",
    "#         #     one_hot[xs == category, i] = 1\n",
    "#         # return one_hot\n",
    "#         # If categories are not specified, infer them from the data.\n",
    "#         # Check if `xs` has more than 1 feature.\n",
    "#         if xs.ndim > 1:\n",
    "#             raise ValueError(\"`OneHotEncoder` only supports array with a single feature\")\n",
    "# \n",
    "#         # Create a binary matrix for each category.\n",
    "#         encoded = np.zeros((len(xs), len(self.categories)))\n",
    "#         for i, x in enumerate(xs):\n",
    "#             # Convert the `numpy.ndarray` object to a tuple.\n",
    "#             x_tuple = tuple(x)\n",
    "# \n",
    "#             # Get the index of the category in the encoded matrix.\n",
    "#             category_index = self.categories.index(x_tuple)\n",
    "# \n",
    "#             # Set the corresponding element in the encoded matrix to 1.\n",
    "#             encoded[i, category_index] = 1\n",
    "# \n",
    "#     def inverse_transform(self, xs):\n",
    "#         \"\"\"Inverse transform `xs`.\"\"\"\n",
    "# \n",
    "#         # Get the index of the maximum value in each row.\n",
    "#         decoded = np.argmax(xs, axis=1)\n",
    "# \n",
    "#         # Convert the indices back to categories.\n",
    "#         decoded = [self.categories[i] for i in decoded]\n",
    "# \n",
    "#         return decoded\n",
    "#         # xs = xs[:, np.newaxis]\n",
    "#         # \n",
    "#         # # Find the index of the maximum value in each row.\n",
    "#         # max_indices = np.argmax(xs, axis=1)\n",
    "#         # \n",
    "#         # # Convert the max indices back to categories.\n",
    "#         # categories = self.categories_[max_indices]\n",
    "#         # return categories\n",
    "#         ...\n",
    "class OneHotEncoder:\n",
    "    def __init__(self, categories, handle_unknown=\"ignore\"):\n",
    "        \"\"\"Initialize the OneHotEncoder with the categories to encode and the handling of unknown categories.\"\"\"\n",
    "        self.categories = categories\n",
    "        self.num_categories = len(categories)\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, xs):\n",
    "        \"\"\"Fit the OneHotEncoder to the data `xs`.\"\"\"\n",
    "        self.categories = jnp.unique(xs)\n",
    "        self.num_categories = len(self.categories)\n",
    "        return self\n",
    "\n",
    "    def transform(self, xs):\n",
    "        \"\"\"Transform the data `xs` using one-hot encoding.\"\"\"\n",
    "        encoded_xs = jnp.zeros((xs.shape[0], self.num_categories))\n",
    "        for i, category in enumerate(self.categories):\n",
    "            encoded_xs[:, i] = xs == category\n",
    "        return encoded_xs\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        \"\"\"Inverse transform the data `xs` using one-hot encoding.\"\"\"\n",
    "        decoded_xs = jnp.zeros(xs.shape[0])\n",
    "        for i, category in enumerate(self.categories):\n",
    "            decoded_xs[xs[:, i] == 1] = category\n",
    "        return decoded_xs\n",
    "\n",
    "    def encode(self, xs):\n",
    "        \"\"\"Encode the data `xs` using one-hot encoding.\n",
    "\n",
    "        Args:\n",
    "            xs: A JAX array of shape (n_samples, 1).\n",
    "\n",
    "        Returns:\n",
    "            A JAX array of shape (n_samples, num_categories).\n",
    "        \"\"\"\n",
    "\n",
    "        encoded_xs = self.transform(xs)\n",
    "\n",
    "        if self.handle_unknown == \"ignore\":\n",
    "            # Ignore any new categories that were not seen during training.\n",
    "            encoded_xs = encoded_xs[:, : self.num_categories]\n",
    "        elif self.handle_unknown == \"error\":\n",
    "            # Raise an error if a new category is encountered.\n",
    "            new_categories = jnp.setdiff1d(xs, self.categories)\n",
    "            if len(new_categories) > 0:\n",
    "                raise ValueError(\n",
    "                    f\"Encountered new categories during encoding: {new_categories}\"\n",
    "                )\n",
    "\n",
    "        return encoded_xs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T14:42:34.924826489Z",
     "start_time": "2023-10-20T14:42:34.883717576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T14:42:35.902993568Z",
     "start_time": "2023-10-20T14:42:35.899095354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdaus/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/firdaus/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!!! Do not edit things below.\n",
    "xs = np.random.choice([0, 1, 2], size=(100, 1))\n",
    "enc = OneHotEncoder().fit(xs)\n",
    "transformed_xs = enc.transform(xs)\n",
    "assert np.array_equal(\n",
    "    transformed_xs,\n",
    "    skp.OneHotEncoder(sparse=False).fit_transform(xs)\n",
    ")\n",
    "assert np.all(enc.inverse_transform(transformed_xs) == xs)\n",
    "\n",
    "xs = np.array([0, 1, 2, np.nan, 0, 1, 2, np.nan], dtype=object).reshape(-1, 1)\n",
    "enc = OneHotEncoder().fit(xs)\n",
    "transformed_xs = enc.transform(xs)\n",
    "assert np.array_equal(\n",
    "    transformed_xs,\n",
    "    skp.OneHotEncoder(sparse=False).fit_transform(xs)\n",
    ")\n",
    "assert np.all(enc.inverse_transform(transformed_xs) == xs.astype(str))\n",
    "\n",
    "# It will fail if `xs` has more than 1 feature.\n",
    "xs = xs.reshape(-1, 2)\n",
    "enc = OneHotEncoder()\n",
    "test_fail(lambda: enc.fit_transform(xs), \n",
    "          contains=\"`OneHotEncoder` only supports array with a single feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T14:42:37.785990727Z",
     "start_time": "2023-10-20T14:42:37.780232465Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Feature:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        data: np.ndarray,\n",
    "        preprocessor: DataPreprocessor = None,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def transform(self, xs):\n",
    "        return self.preprocessor.transform(xs)\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        return self.preprocessor.inverse_transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T14:42:38.851527644Z",
     "start_time": "2023-10-20T14:42:38.844596149Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeaturesList:\n",
    "    def __init__(self, features: list[Feature]):\n",
    "        self.features = features\n",
    "    \n",
    "    def transform(self, xs):\n",
    "        \"\"\"Transform `xs`.\"\"\"\n",
    "        transformed_xs = np.empty((xs.shape[0], 0), dtype=np.float32)\n",
    "        for feat in self.features:\n",
    "            transformed_xs = np.concatenate([transformed_xs, feat.transform(xs)], axis=1)\n",
    "        return transformed_xs\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        \"\"\"Inverse transform `xs`.\"\"\"\n",
    "        inv_xs = np.empty((xs.shape[0], 0), dtype=np.float32)\n",
    "        for feat in self.features:\n",
    "            inv_xs = np.concatenate([inv_xs, feat.inverse_transform(xs)], axis=1)\n",
    "        return inv_xs\n",
    "    # def transform(self, xs):\n",
    "    #     transformed_xs = []\n",
    "    #     for feature in self.features:\n",
    "    #         transformed_xs.append(feature.transform(xs[:, feature.name]))\n",
    "    #     return jnp.concatenate(transformed_xs, axis=1)\n",
    "    # \n",
    "    # def inverse_transform(self, xs):\n",
    "    #     inverse_transformed_xs = []\n",
    "    #     for i in range(len(self.features)):\n",
    "    #         inverse_transformed_xs.append(self.features[i].inverse_transform(xs[:, i]))\n",
    "    #     return jnp.concatenate(inverse_transformed_xs, axis=1)\n",
    "# class FeaturesList:\n",
    "#     def __init__(self, features: list[Feature]):\n",
    "#         self.features = features\n",
    "# \n",
    "#     def transform(self, xs):\n",
    "#         transformed_xs = []\n",
    "#         for i, feature in enumerate(self.features):\n",
    "#             transformed_xs.append(feature.transform(xs[:, i]))\n",
    "#         return np.concatenate(transformed_xs, axis=-1)\n",
    "# \n",
    "#     def inverse_transform(self, xs):\n",
    "#         inverse_transformed_xs = []\n",
    "#         for i, feature in enumerate(self.features):\n",
    "#             inverse_transformed_xs.append(feature.inverse_transform(xs[:, i]))\n",
    "#         return np.concatenate(inverse_transformed_xs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[256], line 25\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m transformed_xs\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m8\u001B[39m)\n\u001B[1;32m     24\u001B[0m inv_xs \u001B[38;5;241m=\u001B[39m feats_list\u001B[38;5;241m.\u001B[39minverse_transform(transformed_xs)\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(test_xs, inv_xs)\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#!!! Do not edit things below.\n",
    "train_xs = np.concatenate([\n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, 2], size=(100, 1)), \n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, np.nan], size=(100, 1)),\n",
    "], axis=-1)\n",
    "test_xs = np.concatenate([\n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, 2], size=(100, 1)), \n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, np.nan], size=(100, 1)),\n",
    "], axis=-1)\n",
    "\n",
    "feats = [\n",
    "    Feature(\"a\", train_xs[:, 0], MinMaxScaler()),\n",
    "    Feature(\"b\", train_xs[:, 1], OneHotEncoder()),\n",
    "    Feature(\"c\", train_xs[:, 2], MinMaxScaler()),\n",
    "    Feature(\"d\", train_xs[:, -1], OneHotEncoder()),\n",
    "]\n",
    "feats_list = FeaturesList(feats)\n",
    "transformed_xs = feats_list.transform(test_xs)\n",
    "assert transformed_xs.shape == (100, 8)\n",
    "inv_xs = feats_list.inverse_transform(transformed_xs)\n",
    "assert np.allclose(test_xs, inv_xs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T14:42:39.206067214Z",
     "start_time": "2023-10-20T14:42:39.156438115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "#!!! Do not edit things below.\n",
    "ct = ColumnTransformer([\n",
    "    (\"a\", skp.MinMaxScaler(), [0]),\n",
    "    (\"b\", skp.OneHotEncoder(), [1]),\n",
    "    (\"c\", skp.MinMaxScaler(), [2]),\n",
    "    (\"d\", skp.OneHotEncoder(), [3]),\n",
    "])\n",
    "sk_transformed_xs = ct.fit_transform(test_xs)\n",
    "assert np.allclose(transformed_xs, sk_transformed_xs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T14:42:40.691988404Z",
     "start_time": "2023-10-20T14:42:40.690700874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T13:41:24.561460357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T01:17:49.182481490Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
