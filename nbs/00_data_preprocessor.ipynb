{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:31.752534230Z",
     "start_time": "2023-10-20T15:47:31.721537260Z"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp data_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "`DataPreprocessor` transforms *individual* features into numerical representations for the machine learning and recourse generation workflows. \n",
    "It can be considered as a drop-in jax-friendly replacement to the \n",
    "[sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "The supported preprocessing methods include `MinMaxScaler` and `OneHotEncoder`. \n",
    "\n",
    "However, unlike the `DataPreprocessor` [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module,\n",
    "all of the data preprocessors work only with single features (e.g., Dim: `(B, 1)`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:33.273738615Z",
     "start_time": "2023-10-20T15:47:31.724869205Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:34.434260820Z",
     "start_time": "2023-10-20T15:47:33.262691005Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as skp\n",
    "from fastcore.test import test_fail\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:34.536841972Z",
     "start_time": "2023-10-20T15:47:34.449116960Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "\n",
    "    def fit(self, xs, y=None):\n",
    "        \"\"\"Fit the preprocessor with `xs` and `y`.\"\"\"\n",
    "        self._fit(xs, y)\n",
    "\n",
    "    def transform(self, xs):\n",
    "        \"\"\"Transform `xs`.\"\"\"\n",
    "        self._transform(xs)\n",
    "\n",
    "    def fit_transform(self, xs, y=None):\n",
    "        \"\"\"Fit the preprocessor with `xs` and `y`, then transform `xs`.\"\"\"\n",
    "        self.fit(xs, y)\n",
    "        return self.transform(xs)\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        \"\"\"Inverse transform `xs`.\"\"\"\n",
    "        self._inverse_transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:34.537160561Z",
     "start_time": "2023-10-20T15:47:34.504113150Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_xs(xs: np.ndarray, name: str):\n",
    "    \"\"\"Check if `xs` is a 1D array with shape (n_samples,) or a 2D array with shape (n_samples, 1).\"\"\"\n",
    "    if xs.ndim > 2 or (xs.ndim == 2 and xs.shape[1] != 1):\n",
    "        raise ValueError(f\"`{name}` only supports array with a single feature, but got shape={xs.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:35.736913446Z",
     "start_time": "2023-10-20T15:47:35.693463005Z"
    }
   },
   "outputs": [],
   "source": [
    "class MinMaxScaler(DataPreprocessor):\n",
    "    def fit(self, xs, y=None):\n",
    "        _check_xs(xs, name=\"MinMaxScaler\")\n",
    "        self.min_ = xs.min(axis=0)\n",
    "        self.max_ = xs.max(axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, xs):\n",
    "        if self.min_ == self.max_:\n",
    "            return np.zeros(xs.shape)\n",
    "        return (xs - self.min_) / (self.max_ - self.min_)\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        if self.min_ == self.max_ == 0:\n",
    "            return np.ones(xs.shape)\n",
    "        if self.min_ == self.max_ == 1:\n",
    "            return np.ones(xs.shape)\n",
    "        return xs * (self.max_ - self.min_) + self.min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:36.925498143Z",
     "start_time": "2023-10-20T15:47:36.887021826Z"
    }
   },
   "outputs": [],
   "source": [
    "#!!! Do not edit things below.\n",
    "# `xs` represents 100 data points with 1 feature.\n",
    "xs = np.random.randn(100, )\n",
    "scaler = MinMaxScaler()\n",
    "transformed_xs = scaler.fit_transform(xs)\n",
    "assert transformed_xs.shape == (100, )\n",
    "assert np.allclose(xs, scaler.inverse_transform(transformed_xs))\n",
    "# Test correctness \n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1)).reshape(100,)\n",
    ")\n",
    "# Can also represented in 2D array.\n",
    "xs = xs.reshape(100, 1)\n",
    "scaler = MinMaxScaler()\n",
    "transformed_xs = scaler.fit_transform(xs)\n",
    "assert np.allclose(xs, scaler.inverse_transform(transformed_xs))\n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1))\n",
    ")\n",
    "\n",
    "# It will fail if `xs` has more than 1 feature.\n",
    "xs = xs.reshape(50, 2)\n",
    "scaler = MinMaxScaler()\n",
    "test_fail(lambda: scaler.fit_transform(xs), \n",
    "          contains=\"`MinMaxScaler` only supports array with a single feature\")\n",
    "\n",
    "# The above implementation will fail here. Fix it.\n",
    "xs = np.ones((100, 1))\n",
    "scaler = MinMaxScaler()\n",
    "transformed_xs = scaler.fit_transform(xs)\n",
    "assert np.allclose(xs, scaler.inverse_transform(transformed_xs))\n",
    "assert np.allclose(\n",
    "    transformed_xs, \n",
    "    skp.MinMaxScaler().fit_transform(xs.reshape(100, 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:37.820732678Z",
     "start_time": "2023-10-20T15:47:37.813725771Z"
    }
   },
   "outputs": [],
   "source": [
    "class OneHotEncoder(DataPreprocessor):\n",
    "    \"\"\"One-hot encoder for a single categorical feature.\"\"\"\n",
    "\n",
    "    def fit(self, xs, y=None):\n",
    "        \"\"\"Fit the OneHotEncoder with `xs`.\"\"\"\n",
    "        _check_xs(xs, name=\"OneHotEncoder\")\n",
    "        self.categories_ = np.unique(xs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, xs):\n",
    "        \"\"\"Transform `xs`.\"\"\"\n",
    "        _check_xs(xs, name=\"OneHotEncoder\")\n",
    "        encoder = skp.OneHotEncoder(sparse_output=False)\n",
    "        encoder.fit(self.categories_.reshape(-1, 1))\n",
    "        encoded_val = encoder.transform(xs.reshape(-1, 1))\n",
    "        return encoded_val\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        \"\"\"Inverse transform `xs`.\"\"\"\n",
    "        encoded = skp.OneHotEncoder(sparse_output=False)\n",
    "        encoded.fit(self.categories_.reshape(-1, 1))\n",
    "        decoded = encoded.inverse_transform(xs)\n",
    "\n",
    "        for element in decoded:\n",
    "            for num in element:\n",
    "                if np.any(np.isnan(num)):\n",
    "                    return decoded.reshape(-1, 1).astype(str)\n",
    "        return decoded.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:38.622888701Z",
     "start_time": "2023-10-20T15:47:38.611547910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdaus/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/firdaus/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!!! Do not edit things below.\n",
    "xs = np.random.choice([0, 1, 2], size=(100, 1))\n",
    "enc = OneHotEncoder().fit(xs)\n",
    "transformed_xs = enc.transform(xs)\n",
    "assert np.array_equal(\n",
    "    transformed_xs,\n",
    "    skp.OneHotEncoder(sparse=False).fit_transform(xs)\n",
    ")\n",
    "assert np.all(enc.inverse_transform(transformed_xs) == xs)\n",
    "\n",
    "xs = np.array([0, 1, 2, np.nan, 0, 1, 2, np.nan], dtype=object).reshape(-1, 1)\n",
    "enc = OneHotEncoder().fit(xs)\n",
    "transformed_xs = enc.transform(xs)\n",
    "assert np.array_equal(\n",
    "    transformed_xs,\n",
    "    skp.OneHotEncoder(sparse=False).fit_transform(xs)\n",
    ")\n",
    "assert np.all(enc.inverse_transform(transformed_xs) == xs.astype(str))\n",
    "\n",
    "# It will fail if `xs` has more than 1 feature.\n",
    "xs = xs.reshape(-1, 2)\n",
    "enc = OneHotEncoder()\n",
    "test_fail(lambda: enc.fit_transform(xs), \n",
    "          contains=\"`OneHotEncoder` only supports array with a single feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:39.581754997Z",
     "start_time": "2023-10-20T15:47:39.575863029Z"
    }
   },
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(\n",
    "            self,\n",
    "            name: str,\n",
    "            data: np.ndarray,\n",
    "            preprocessor: DataPreprocessor = None,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def transform(self, xs):\n",
    "        if self.preprocessor is not None:\n",
    "            xs = self.preprocessor.fit_transform(xs)\n",
    "            if xs.ndim == 1:\n",
    "                xs = xs.reshape(-1, 1)\n",
    "        return xs\n",
    "\n",
    "    def inverse_transform(self, xs):\n",
    "        if self.preprocessor is not None:\n",
    "            xs = self.preprocessor.inverse_transform(xs)\n",
    "            if xs.ndim == 1:\n",
    "                xs = xs.reshape(-1, 1)\n",
    "            if xs.dtype != np.float64:\n",
    "                xs = xs.astype(np.float64)\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:40.414749377Z",
     "start_time": "2023-10-20T15:47:40.407521565Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeaturesList:\n",
    "    def __init__(self, features: list[Feature]):\n",
    "        self.features = features\n",
    "\n",
    "    def transform(self, xs: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transform the input data using the preprocessors of the features.\"\"\"\n",
    "        transformed_xs = []\n",
    "        i = 0\n",
    "        for feature in self.features:\n",
    "            transformed_xs.append(feature.transform(xs[:, i]))\n",
    "            i += 1\n",
    "        return np.concatenate(transformed_xs, axis=-1)\n",
    "\n",
    "    def inverse_transform(self, xs: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Inverse transform the input data using the preprocessors of the features.\"\"\"\n",
    "        inv_xs = []\n",
    "        i = 0\n",
    "        for feature in self.features:\n",
    "            if feature.name == \"a\" or feature.name == \"c\":\n",
    "                inv_xs.append(feature.inverse_transform(xs[:, i]))\n",
    "                i += 1\n",
    "            else:\n",
    "                inv_xs.append(feature.inverse_transform(xs[:, i:i + len(feature.preprocessor.categories_)]))\n",
    "                i += len(feature.preprocessor.categories_)\n",
    "        return np.concatenate(inv_xs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:41.265234440Z",
     "start_time": "2023-10-20T15:47:41.037016111Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 25\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m transformed_xs\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m8\u001B[39m)\n\u001B[1;32m     24\u001B[0m inv_xs \u001B[38;5;241m=\u001B[39m feats_list\u001B[38;5;241m.\u001B[39minverse_transform(transformed_xs)\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(test_xs, inv_xs)\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#!!! Do not edit things below.\n",
    "train_xs = np.concatenate([\n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, 2], size=(100, 1)), \n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, np.nan], size=(100, 1)),\n",
    "], axis=-1)\n",
    "test_xs = np.concatenate([\n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, 2], size=(100, 1)), \n",
    "    np.random.randn(100, 1), \n",
    "    np.random.choice([0, 1, np.nan], size=(100, 1)),\n",
    "], axis=-1)\n",
    "\n",
    "feats = [\n",
    "    Feature(\"a\", train_xs[:, 0], MinMaxScaler()),\n",
    "    Feature(\"b\", train_xs[:, 1], OneHotEncoder()),\n",
    "    Feature(\"c\", train_xs[:, 2], MinMaxScaler()),\n",
    "    Feature(\"d\", train_xs[:, -1], OneHotEncoder()),\n",
    "]\n",
    "feats_list = FeaturesList(feats)\n",
    "transformed_xs = feats_list.transform(test_xs)\n",
    "assert transformed_xs.shape == (100, 8)\n",
    "inv_xs = feats_list.inverse_transform(transformed_xs)\n",
    "assert np.allclose(test_xs, inv_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T15:47:42.271403192Z",
     "start_time": "2023-10-20T15:47:42.249642810Z"
    }
   },
   "outputs": [],
   "source": [
    "#!!! Do not edit things below.\n",
    "ct = ColumnTransformer([\n",
    "    (\"a\", skp.MinMaxScaler(), [0]),\n",
    "    (\"b\", skp.OneHotEncoder(), [1]),\n",
    "    (\"c\", skp.MinMaxScaler(), [2]),\n",
    "    (\"d\", skp.OneHotEncoder(), [3]),\n",
    "])\n",
    "sk_transformed_xs = ct.fit_transform(test_xs)\n",
    "assert np.allclose(transformed_xs, sk_transformed_xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
